{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to prepare the dataset by preprocessing, cleaning, and selecting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('bmh')\n",
    "mpl.rcParams.update({\n",
    "    \"grid.linestyle\" : \"dashed\",\n",
    "    \"axes.facecolor\" : \"white\",\n",
    "    \"axes.spines.top\" : False,\n",
    "    \"axes.spines.right\" : False,\n",
    "    \"legend.frameon\" : False,\n",
    "    \"figure.figsize\" : (8, 5),\n",
    "    \"figure.dpi\" : 300,\n",
    "})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter CVD Death Patients\n",
    "Remove all the NON-CVD death patients. Here we take in input the original dataset and output the original dataset with only CVD Death patients:\n",
    "- Input: data.csv\n",
    "- Output: data_cvd.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"./data/raw/data_raw.csv\", index_col=0, decimal='.')\n",
    "df.convert_dtypes()\n",
    "df[\"Follow Up Data\"] = pd.to_datetime(df[\"Follow Up Data\"], format=\"%m/%d/%Y\")\n",
    "df[\"Data prelievo\"] = pd.to_datetime(df[\"Data prelievo\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vessels = pd.read_csv(\"./data/raw/data_vessels.csv\", index_col=0, decimal='.')\n",
    "print(\"Missing vessels (before):\", df[\"Vessels\"].isna().sum())\n",
    "\n",
    "df[\"Vessels\"] = df_vessels[\"NEW-Vessels\"]\n",
    "df[\"Creatinina\"] = df_vessels[\"Creatinina\"]\n",
    "print(\"Missing vessels (after):\", df[\"Vessels\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NA values\n",
    "df[\"Vessels\"] += 1\n",
    "df[\"Vessels\"] = df[\"Vessels\"].fillna(0)\n",
    "df[\"Creatinina\"] = df[\"Creatinina\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ONLY and ALL the deaths patients NON-CVD (Fatal MI or Sudden death, UnKnown, Accident, Suicide)\n",
    "total = df[df[\"Total mortality\"]==1].index\n",
    "cvd_idx = df[df[\"CVD Death\"]==1].index\n",
    "noncvd_idx = set(total) - set(cvd_idx)\n",
    "\n",
    "print(f\"Total deaths: {len(total)}\")\n",
    "print(f\"Death CVD: {len(cvd_idx)}\")\n",
    "print(f\"Death Non-CVD: {len(noncvd_idx)}\")\n",
    "\n",
    "df_cvd = df.drop(noncvd_idx)\n",
    "print(f\"\\nTotal patients: {len(df)}\")\n",
    "print(f\"Total patients (after removal of Death Non-CVD): {len(df_cvd)}\")\n",
    "\n",
    "assert len(noncvd_idx) == len(total) - len(cvd_idx)\n",
    "assert len(df.columns) == len(df_cvd.columns)\n",
    "# df_cvd.to_csv(\"data/raw/data_cvd.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Irrelevant Features\n",
    "From the only CVD death patients, we remove all the irrelevant features for the classification task. We also create a target feature. \n",
    "- Input: data_cvd.csv\n",
    "- Output: data_cvd_clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cvd = pd.read_csv(\"./data/raw/data_cvd.csv\", index_col=0, decimal='.')\n",
    "df_cvd[\"Follow Up Data\"] = pd.to_datetime(df_cvd[\"Follow Up Data\"])\n",
    "df_cvd[\"Data prelievo\"] = pd.to_datetime(df_cvd[\"Data prelievo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference between dates: follow up and admission\n",
    "figure = plt.figure()\n",
    "df_diff = (df_cvd[\"Follow Up Data\"] - df_cvd[\"Data prelievo\"]).map(lambda x: x.days // 365)\n",
    "df_diff.value_counts(normalize=True).sort_index().plot(kind='bar', figsize=(8,5), ax=plt.gca())\n",
    "plt.title(\"Distribution of the difference between Follow up - Recovery\")\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete vessels feature, if CAD == 0 then Vessels can be set to 0, otherwise we don't know the Vessels\n",
    "for i in df_cvd.index:\n",
    "    if (pd.isna(df_cvd[\"Vessels\"][i]) and df_cvd[\"CAD\"][i]==0):\n",
    "        df_cvd.loc[i, \"Vessels\"] = 0\n",
    "    elif (pd.isna(df_cvd[\"Vessels\"][i]) and df_cvd[\"CAD\"][i]==1):\n",
    "        df_cvd.loc[i, \"Vessels\"] = -1\n",
    "\n",
    "# Clean features remove follow up features\n",
    "df_feat = df_cvd.copy()\n",
    "df_feat = pd.concat([df_feat.iloc[:, :30], df_feat.iloc[:, 40:]], axis=1)\n",
    "df_feat = df_feat.drop(columns=[\"Data of death\", \"Data prelievo\", \"Follow Up Data\", \"Durata Follow Up\",\n",
    "                                \"Fatal MI or Sudden death\", \"UnKnown\", \"Accident\", \"Total mortality\", \n",
    "                                \"CVD Death\", \"CAD\"])\n",
    "\n",
    "# Create and add target feature `Survive`\n",
    "years = 7\n",
    "survive = (df_diff < years) & df_cvd[\"CVD Death\"]\n",
    "survive = (survive + 1) % 2\n",
    "df_feat[f\"Survive{years}Y\"] = survive\n",
    "\n",
    "print(\"Total patient: \\t\", len(df_feat))\n",
    "print(\"Survived: \\t\", df_feat[f\"Survive{years}Y\"].sum(), \"\\t\", df_feat[f\"Survive{years}Y\"].sum()/len(df_feat))\n",
    "print(\"Dead: \\t\\t\", len(df_feat)-df_feat[f\"Survive{years}Y\"].sum(), \"\\t\", (len(df_feat)-df_feat[f\"Survive{years}Y\"].sum())/len(df_feat))\n",
    "df_feat = df_feat.convert_dtypes()\n",
    "\n",
    "# df_feat.to_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra\n",
    "Create and save the subset datagroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset train, valid, test split\n",
    "def split_and_save(df, path, verbose=True):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, stratify=df.iloc[:,-1])\n",
    "    df_train, df_valid = train_test_split(df_train, test_size=0.25, stratify=df_train.iloc[:,-1])\n",
    "\n",
    "    df_train.to_csv(f\"{path}train.csv\")\n",
    "    df_valid.to_csv(f\"{path}valid.csv\")\n",
    "    df_test.to_csv(f\"{path}test.csv\")\n",
    "\n",
    "    if verbose: \n",
    "        print(\"Train: \\t\", len(df_train))\n",
    "        print(\"Valid: \\t\", len(df_valid))\n",
    "        print(\"Test: \\t\", len(df_test))\n",
    "\n",
    "# split_and_save(df_feat, \"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/7y/train.csv\", index_col=0, decimal='.')\n",
    "df_valid = pd.read_csv(\"./data/7y/valid.csv\", index_col=0, decimal='.')\n",
    "df_test = pd.read_csv(\"./data/7y/test.csv\", index_col=0, decimal='.')\n",
    "\n",
    "df_train_new = df_feat.loc[df_train.index, :]\n",
    "df_valid_new = df_feat.loc[df_valid.index, :]\n",
    "df_test_new = df_feat.loc[df_test.index, :]\n",
    "\n",
    "path = \"data\"\n",
    "df_train_new.to_csv(f\"{path}/train.csv\")\n",
    "df_valid_new.to_csv(f\"{path}/valid.csv\")\n",
    "df_test_new.to_csv(f\"{path}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_train = pd.read_csv(\"./data/train.csv\", index_col=0, decimal='.')\n",
    "df_valid = pd.read_csv(\"./data/valid.csv\", index_col=0, decimal='.')\n",
    "df_test = pd.read_csv(\"./data/test.csv\", index_col=0, decimal='.')\n",
    "print(Counter(df_train[\"Survive7Y\"]))\n",
    "print(Counter(df_valid[\"Survive7Y\"]))\n",
    "print(Counter(df_test[\"Survive7Y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# fig, ax = plt.subplots(figsize=(35,30))\n",
    "# sns.heatmap(df_feat.corr(), annot=True)\n",
    "# # fig.savefig(\"feat.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('natpn-improve')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5688027ca59d69ed77c02998d74f34c37d32890800deaafdffc8abeb6170b97d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
