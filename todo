todo ==========================================================
    overfit on training set to check 
    report also training metrics
    check wether the same samples are wrong on all the classifiers or not

  feature selection
    recursive feature elimination (RFE)
    sequential feature selection (SFS)
    select from model using feature importance
    permutation importance measure variable's importance

  visualize the wrong classified data (visualize the worst)
  test X years, raising years make the data more balanced
  lifelines library: uni/multivariate cox model is used to find the important predictors
  
  add dropped samples to the validation set
  try adaboost, gtb

  1. select metric: predict probabilities or labels
    - AUC, is positive or negative class more important? PR AUC when positive class is most important
    - F2 if false negatives are more costly, F0.5 opposite
  2. check ml algorithms
  3. check unbalanced algorithms
  3. hyperparameter tuning


done ==========================================================
  feature selection
    univariate feature selection (SelectKBest, chi2)

  unbalancement
    predicting probs and modifying threshold controls the FP, FN 
    undersampling, oversampling (SMOTE): helps to reduce FP as penalized models!
    penalized model: helps to reduce FP!
    f1, auc, balanced accuracy

  visualize PCA, T-SNE: T-SNE shows a subtle division between healthy and sick patients
  feature scaling: standardization helps to increase a bit F1-macro
